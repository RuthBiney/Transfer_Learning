{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMp+wv6E1x2to8bKzk+qo1q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RuthBiney/Transfer_Learning/blob/main/Transfer_Learning_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Step-by-Step Plan:\n",
        "\n",
        "Dataset Preparation: We'll use the three categories (wine, beer, whiskey) for classification. We will load and preprocess the images.\n",
        "\n",
        "Pre-trained Models Setup: We'll load three pre-trained models: VGG16, ResNet50, and InceptionV3, and fine-tune them for this classification task.\n",
        "\n",
        "Training and Fine-tuning: We'll modify the pre-trained models to adapt to your dataset and train them.\n",
        "\n",
        "Evaluation: We'll compare the models' performance using metrics like Accuracy, Loss, Precision, Recall, and F1-score."
      ],
      "metadata": {
        "id": "V3yhAkeyGYs6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Step 1: Dataset Preparation\n",
        "\n",
        "Let's start by loading and preparing the dataset using Keras' ImageDataGenerator. We’ll split the dataset into training and validation sets and apply augmentations.\n",
        "\n"
      ],
      "metadata": {
        "id": "c2rPs0u2NoBa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLtEZR2tGW33",
        "outputId": "e140824c-2324-41f0-e0ee-e18d585e3d39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1365 images belonging to 3 classes.\n",
            "Found 340 images belonging to 3 classes.\n"
          ]
        }
      ],
      "source": [
        "# Use the correct path where the dataset is unzipped\n",
        "dataset_path = '/content/Alcohol_Dataset'\n",
        "\n",
        "# Data Augmentation and Preprocessing\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,          # Normalize pixel values\n",
        "    rotation_range=20,       # Random rotation\n",
        "    width_shift_range=0.2,   # Horizontal shift\n",
        "    height_shift_range=0.2,  # Vertical shift\n",
        "    shear_range=0.2,         # Shear transformation\n",
        "    zoom_range=0.2,          # Zoom\n",
        "    horizontal_flip=True,    # Random horizontal flip\n",
        "    validation_split=0.2,    # Split 20% for validation\n",
        "    fill_mode='nearest'      # Fill missing pixels\n",
        ")\n",
        "\n",
        "# Training data generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    dataset_path,\n",
        "    target_size=(224, 224),  # Resize all images to 224x224 (input size for most models)\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',  # Multi-class classification\n",
        "    subset='training'  # Training subset\n",
        ")\n",
        "\n",
        "# Validation data generator\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    dataset_path,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'  # Validation subset\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Step 2: Pre-trained Model Setup\n",
        "\n",
        "1. Load the Pre-trained Models\n",
        "Here, we'll load the models without their top layers, as we'll add our custom layers for classification."
      ],
      "metadata": {
        "id": "P4lDc8OuOlxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import VGG16, ResNet50, InceptionV3\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Load VGG16, ResNet50, and InceptionV3 without the top classification layer\n",
        "vgg16_base = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "resnet50_base = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "inception_base = InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n"
      ],
      "metadata": {
        "id": "g8cOMxOdOugp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d20c839-010b-4d83-b898-9c2887fb9027"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m87910968/87910968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Freeze the Base Layers\n",
        "\n",
        "We’ll freeze the base layers of the pre-trained models so that the learned features remain intact. We will only train the new classification layers."
      ],
      "metadata": {
        "id": "ygpR4iq7O14P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze base layers for all models\n",
        "for layer in vgg16_base.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "for layer in resnet50_base.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "for layer in inception_base.layers:\n",
        "    layer.trainable = False\n"
      ],
      "metadata": {
        "id": "HGftvuEYO55W"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Add Custom Layers for Classification\n",
        "\n",
        "We’ll add custom dense layers after the base models to handle the classification task (between wine, beer, and whiskey)."
      ],
      "metadata": {
        "id": "mY1nTBAuPI0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_custom_layers(base_model):\n",
        "    # Flatten the output of the base model\n",
        "    x = Flatten()(base_model.output)\n",
        "    # Add a fully connected layer\n",
        "    x = Dense(1024, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)  # Add dropout for regularization\n",
        "    # Final output layer with 3 units (for 3 classes) and softmax activation\n",
        "    output = Dense(3, activation='softmax')(x)  # 3 classes: wine, beer, whiskey\n",
        "\n",
        "    # Create the final model\n",
        "    model = Model(base_model.input, output)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "BGd2xcNzPODG"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Compile the Models\n",
        "\n",
        "We'll compile the models using an Adam optimizer and categorical_crossentropy loss (since this is a multi-class classification problem)."
      ],
      "metadata": {
        "id": "UJR8-OiTQFfR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add custom layers to the pre-trained models\n",
        "vgg16_model = add_custom_layers(vgg16_base)\n",
        "resnet50_model = add_custom_layers(resnet50_base)\n",
        "inception_model = add_custom_layers(inception_base)\n",
        "\n",
        "# Compile the models\n",
        "vgg16_model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "resnet50_model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "inception_model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "bqf72MCcQKdC"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Step 3: Training the Models\n",
        "\n",
        "Now that the models are compiled, we can train them on the dataset using the training and validation generators we set up earlier."
      ],
      "metadata": {
        "id": "5kiDA4gJQPWr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train VGG16 model\n",
        "vgg16_history = vgg16_model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
        "    epochs=10  # You can adjust the number of epochs based on performance\n",
        ")\n",
        "\n",
        "# Train ResNet50 model\n",
        "resnet50_history = resnet50_model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
        "    epochs=10\n",
        ")\n",
        "\n",
        "# Train InceptionV3 model\n",
        "inception_history = inception_model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
        "    epochs=10\n",
        ")\n"
      ],
      "metadata": {
        "id": "ZFqO88PcQTto",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb6f4fcb-d924-47cc-9540-26e40095da86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21s/step - accuracy: 0.4722 - loss: 1.1830 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1087s\u001b[0m 26s/step - accuracy: 0.4744 - loss: 1.1785 - val_accuracy: 0.8094 - val_loss: 0.4702\n",
            "Epoch 2/10\n",
            "\u001b[1m 1/42\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m15:25\u001b[0m 23s/step - accuracy: 0.5312 - loss: 1.0352"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 280ms/step - accuracy: 0.5312 - loss: 1.0352 - val_accuracy: 0.7500 - val_loss: 0.5996\n",
            "Epoch 3/10\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1217s\u001b[0m 28s/step - accuracy: 0.7046 - loss: 0.6936 - val_accuracy: 0.7969 - val_loss: 0.5340\n",
            "Epoch 4/10\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 306ms/step - accuracy: 0.8125 - loss: 0.4755 - val_accuracy: 0.7500 - val_loss: 0.4829\n",
            "Epoch 5/10\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1326s\u001b[0m 31s/step - accuracy: 0.7244 - loss: 0.6744 - val_accuracy: 0.7812 - val_loss: 0.5313\n",
            "Epoch 6/10\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 1s/step - accuracy: 0.8125 - loss: 0.5076 - val_accuracy: 0.9000 - val_loss: 0.3279\n",
            "Epoch 7/10\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1096s\u001b[0m 26s/step - accuracy: 0.7805 - loss: 0.5767 - val_accuracy: 0.8500 - val_loss: 0.3960\n",
            "Epoch 8/10\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 304ms/step - accuracy: 0.8438 - loss: 0.6964 - val_accuracy: 0.8500 - val_loss: 0.3710\n",
            "Epoch 9/10\n",
            "\u001b[1m20/42\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m7:31\u001b[0m 21s/step - accuracy: 0.7931 - loss: 0.5483"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Step 4: Model Evaluation\n",
        "\n",
        "Once training is complete, we can evaluate the model's performance on the validation set using metrics such as accuracy, precision, recall, and F1-score. Here’s how you can evaluate the models:"
      ],
      "metadata": {
        "id": "pd_y0jLIYzmA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Get predictions from the VGG16 model\n",
        "val_preds_vgg = vgg16_model.predict(validation_generator)\n",
        "val_preds_vgg = val_preds_vgg.argmax(axis=1)  # Get the predicted class index\n",
        "\n",
        "# Get true labels\n",
        "true_labels = validation_generator.classes\n",
        "\n",
        "# Classification report for VGG16\n",
        "print(\"VGG16 Model Classification Report\")\n",
        "print(classification_report(true_labels, val_preds_vgg, target_names=validation_generator.class_indices.keys()))\n",
        "\n",
        "# Confusion matrix for VGG16\n",
        "print(\"VGG16 Confusion Matrix\")\n",
        "print(confusion_matrix(true_labels, val_preds_vgg))\n"
      ],
      "metadata": {
        "id": "XSvzkXwfY9F4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Step 5: Visualize Training Progress\n",
        "\n",
        "You can also visualize how the accuracy and loss evolved over the epochs for each model. Here’s the code to plot training history:"
      ],
      "metadata": {
        "id": "qqUfXYlbZG3X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot accuracy for VGG16\n",
        "plt.plot(vgg16_history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(vgg16_history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('VGG16 Model Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot loss for VGG16\n",
        "plt.plot(vgg16_history.history['loss'], label='Train Loss')\n",
        "plt.plot(vgg16_history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('VGG16 Model Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "F8dHr2J_ZMlV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Step 6: Save Your Models\n",
        "\n",
        "If you're satisfied with the models' performance, you can save the trained models to reuse them later without needing to retrain:"
      ],
      "metadata": {
        "id": "E3pGj4IxZUWT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the VGG16 model\n",
        "vgg16_model.save('vgg16_model.h5')\n",
        "\n",
        "# Similarly, save ResNet50 and InceptionV3 models\n",
        "resnet50_model.save('resnet50_model.h5')\n",
        "inception_model.save('inception_model.h5')\n"
      ],
      "metadata": {
        "id": "SOF_T3u-ZY80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Step 7: Model Evaluation\n",
        "\n",
        "We’ll start by generating classification reports and confusion matrices for the validation set. This will help you assess how well the models performed."
      ],
      "metadata": {
        "id": "16yzHWOqcO4W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Get predictions from the VGG16 model\n",
        "val_preds_vgg = vgg16_model.predict(validation_generator)\n",
        "val_preds_vgg = val_preds_vgg.argmax(axis=1)  # Get the predicted class index\n",
        "\n",
        "# Get true labels\n",
        "true_labels = validation_generator.classes\n",
        "\n",
        "# Classification report for VGG16\n",
        "print(\"VGG16 Model Classification Report\")\n",
        "print(classification_report(true_labels, val_preds_vgg, target_names=validation_generator.class_indices.keys()))\n",
        "\n",
        "# Confusion matrix for VGG16\n",
        "print(\"VGG16 Confusion Matrix\")\n",
        "print(confusion_matrix(true_labels, val_preds_vgg))\n"
      ],
      "metadata": {
        "id": "eW-eOGtvcUoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Step 8: Visualize Training Progress\n",
        "To visualize how the models improved over time, we’ll plot the training and validation accuracy and loss over the epochs."
      ],
      "metadata": {
        "id": "9jmLqkSace2G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot accuracy for VGG16\n",
        "plt.plot(vgg16_history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(vgg16_history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('VGG16 Model Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot loss for VGG16\n",
        "plt.plot(vgg16_history.history['loss'], label='Train Loss')\n",
        "plt.plot(vgg16_history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('VGG16 Model Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "zRCcnXwFciKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Step 9: Save Your Models"
      ],
      "metadata": {
        "id": "tX3qsHaYcq3c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the VGG16 model\n",
        "vgg16_model.save('vgg16_model.h5')\n",
        "\n",
        "# Similarly, save ResNet50 and InceptionV3 models\n",
        "resnet50_model.save('resnet50_model.h5')\n",
        "inception_model.save('inception_model.h5')\n"
      ],
      "metadata": {
        "id": "8vrfri0ecuv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Let's proceed with the evaluation of the models and the visualization of the training progress.\n",
        "\n",
        "###Step 1: Model Evaluation (for VGG16)"
      ],
      "metadata": {
        "id": "j4lZOrk8dwSe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Get predictions from the VGG16 model\n",
        "val_preds_vgg = vgg16_model.predict(validation_generator)\n",
        "val_preds_vgg = val_preds_vgg.argmax(axis=1)  # Get the predicted class index\n",
        "\n",
        "# Get true labels\n",
        "true_labels = validation_generator.classes\n",
        "\n",
        "# Classification report for VGG16\n",
        "print(\"VGG16 Model Classification Report\")\n",
        "print(classification_report(true_labels, val_preds_vgg, target_names=validation_generator.class_indices.keys()))\n",
        "\n",
        "# Confusion matrix for VGG16\n",
        "print(\"VGG16 Confusion Matrix\")\n",
        "print(confusion_matrix(true_labels, val_preds_vgg))\n"
      ],
      "metadata": {
        "id": "MXTTCVUid4VD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Step 2: Model Evaluation (for ResNet50 and InceptionV3)"
      ],
      "metadata": {
        "id": "WqCWdwX2eFBn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_preds_resnet = resnet50_model.predict(validation_generator)\n",
        "val_preds_resnet = val_preds_resnet.argmax(axis=1)\n",
        "\n",
        "print(\"ResNet50 Model Classification Report\")\n",
        "print(classification_report(true_labels, val_preds_resnet, target_names=validation_generator.class_indices.keys()))\n",
        "\n",
        "print(\"ResNet50 Confusion Matrix\")\n",
        "print(confusion_matrix(true_labels, val_preds_resnet))\n"
      ],
      "metadata": {
        "id": "8ACJHPqfeIhE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "InceptionV3 Evaluation:"
      ],
      "metadata": {
        "id": "XYT-XSMWeNUD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_preds_inception = inception_model.predict(validation_generator)\n",
        "val_preds_inception = val_preds_inception.argmax(axis=1)\n",
        "\n",
        "print(\"InceptionV3 Model Classification Report\")\n",
        "print(classification_report(true_labels, val_preds_inception, target_names=validation_generator.class_indices.keys()))\n",
        "\n",
        "print(\"InceptionV3 Confusion Matrix\")\n",
        "print(confusion_matrix(true_labels, val_preds_inception))\n"
      ],
      "metadata": {
        "id": "h6Z-KJMHePBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Step 3: Visualization of Training Progress"
      ],
      "metadata": {
        "id": "X9iDoAHLeV3W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot accuracy for VGG16\n",
        "plt.plot(vgg16_history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(vgg16_history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('VGG16 Model Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot loss for VGG16\n",
        "plt.plot(vgg16_history.history['loss'], label='Train Loss')\n",
        "plt.plot(vgg16_history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('VGG16 Model Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "bAz2mLQZeYQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ResNet50 Visualization:"
      ],
      "metadata": {
        "id": "4KTTE2MLeg1m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot accuracy for ResNet50\n",
        "plt.plot(resnet50_history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(resnet50_history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('ResNet50 Model Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot loss for ResNet50\n",
        "plt.plot(resnet50_history.history['loss'], label='Train Loss')\n",
        "plt.plot(resnet50_history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('ResNet50 Model Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "gV2gTG2hel4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "InceptionV3 Visualization:\n"
      ],
      "metadata": {
        "id": "zSdcT_bdep_b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot accuracy for InceptionV3\n",
        "plt.plot(inception_history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(inception_history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('InceptionV3 Model Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot loss for InceptionV3\n",
        "plt.plot(inception_history.history['loss'], label='Train Loss')\n",
        "plt.plot(inception_history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('InceptionV3 Model Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "NBKFiy8kerol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 4: Save Models\n",
        "\n",
        "After evaluating and visualizing, you can save the models as follows:"
      ],
      "metadata": {
        "id": "GXRqkSdBexem"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the VGG16 model\n",
        "vgg16_model.save('vgg16_model.h5')\n",
        "\n",
        "# Save ResNet50 model\n",
        "resnet50_model.save('resnet50_model.h5')\n",
        "\n",
        "# Save InceptionV3 model\n",
        "inception_model.save('inception_model.h5')\n"
      ],
      "metadata": {
        "id": "qLXIGrjae3cX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 5: Interpretation of Results\n",
        "\n",
        "After evaluating the models and visualizing their training performance, let’s break down how to interpret the results.\n",
        "\n",
        "#1. Classification Report:\n",
        "The classification report provides key metrics such as:\n",
        "\n",
        "*   Precision: The ratio of true positive predictions to the total predicted positives.\n",
        "*   Recall: The ratio of true positive predictions to the total actual positives.\n",
        "*   F1-score: The harmonic mean of precision and recall, giving a balanced measure.\n",
        "*   F1-score: The harmonic mean of precision and recall, giving a balanced measure.\n",
        "\n",
        "#2. Confusion Matrix:\n",
        "The confusion matrix shows how well the model predicted the actual labels. Each row corresponds to the actual class, and each column corresponds to the predicted class.\n",
        "\n",
        "*   True Positives: Diagonal values where the predicted and actual labels match.\n",
        "*   False Positives/Negatives: Off-diagonal values, indicating misclassifications.\n",
        "\n",
        "#3. Training and Validation Accuracy/Loss:\n",
        "*   Training Accuracy/Loss: Shows how well the model performed on the training data.\n",
        "*   Validation Accuracy/Loss: Shows how well the model generalizes to unseen data (validation set).\n",
        "      1. If the training accuracy is much higher than the validation accuracy, it may indicate overfitting.\n",
        "      2. If both accuracies are improving together, it’s a good sign of model learning.\n",
        "\n",
        "#Step 6: Comparison of Models\n",
        "Compare the results from VGG16, ResNet50, and InceptionV3:\n",
        "\n",
        "*   Accuracy: Which model achieved the highest validation accuracy?\n",
        "*   Precision/Recall/F1-score: Which model shows a better balance between precision and recall?\n",
        "*   Confusion Matrix: Which model makes fewer misclassifications?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qcSkvTDWgD6D"
      }
    }
  ]
}